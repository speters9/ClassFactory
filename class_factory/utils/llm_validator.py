# %%
import logging
from typing import Any, Dict, Optional

from langchain_core.messages import SystemMessage
from langchain_core.prompts import (ChatPromptTemplate,
                                    HumanMessagePromptTemplate, PromptTemplate)
from pydantic import BaseModel, Field

from class_factory.utils.tools import logger_setup, retry_on_json_decode_error
from class_factory.utils.validator_prompts import (validator_human_prompt,
                                                   validator_system_prompt)

# %%


class ValidatorInterimResponse(BaseModel):
    accuracy: float = Field(..., description="Accuracy score of the LLM's response, on a scale from 0 to 10.")
    completeness: float = Field(..., description="Completeness score of the LLM's response, on a scale from 0 to 10.")
    consistency: float = Field(..., description="Consistency score of the LLM's response, on a scale from 0 to 10.")
    reasoning: str = Field(..., description="Reasoning behind the scores.")
    additional_guidance: str = Field(..., description="Guidance which will be appended to the model's prompt to improve its output.")


class ValidatorResponse(BaseModel):
    overall_score: float
    accuracy: float
    completeness: float
    consistency: float
    reasoning: str
    additional_guidance: str
    status: int

    @classmethod
    def from_interim(cls, interim: ValidatorInterimResponse, threshold: float = 8.0) -> "ValidatorResponse":
        # consistency not required because of structured output requirements
        overall_score = round((interim.accuracy + interim.completeness) / 2.0, 3)
        status = 1 if overall_score >= threshold else 0
        return cls(
            overall_score=overall_score,
            status=status,
            **interim.model_dump()
        )


class Validator:
    """A class for validating responses generated by an LLM (Language Model).

    The Validator checks the accuracy, completeness, and relevance of the LLM's response
    to ensure it meets the requirements specified in the task prompt. Validation results
    include a score, status, reasoning, and any additional guidance.
    """

    def __init__(self, llm: any, temperature: float = 0.2,
                 log_level: int = 20,  # logging.INFO
                 system_prompt: Optional[str] = None,
                 human_prompt: Optional[str] = None,
                 tracer: Optional[any] = None,
                 score_threshold: float = 8.0) -> None:
        self.llm = llm
        self.llm.temperature = temperature
        self.logger = logger_setup(logger_name="validator", log_level=log_level)
        self.system_prompt = system_prompt or validator_system_prompt
        self.human_prompt = human_prompt or validator_human_prompt
        self.tracer = tracer
        self.score_threshold = score_threshold

    @retry_on_json_decode_error()
    def validate(self, task_description: str, generated_response: str, task_schema: str = "", specific_guidance: str = "") -> dict:
        prompt = ChatPromptTemplate.from_messages(
            [
                SystemMessage(content=(self.system_prompt)),
                HumanMessagePromptTemplate.from_template(self.human_prompt)
            ]
        )
        chain = prompt | self.llm.with_structured_output(ValidatorInterimResponse)
        config = {"callbacks": [self.tracer]} if self.tracer else None
        response = chain.invoke({
            "specific_guidance": specific_guidance,
            "task_description": task_description,
            "task_schema": task_schema,
            "generated_response": generated_response,
        }, config=config)
        output = ValidatorResponse.from_interim(response, threshold=self.score_threshold)
        return output.model_dump()


# %%
if __name__ == "__main__":
    import json
    import os
    from pathlib import Path

    # env setup
    from dotenv import load_dotenv
    # llm chain setup
    from langchain_community.llms import Ollama
    from langchain_core.output_parsers import JsonOutputParser
    from langchain_openai import ChatOpenAI
    from pyprojroot.here import here

    from class_factory.concept_web.concept_extraction import (
        extract_relationships, summarize_text)
    from class_factory.concept_web.prompts import (relationship_prompt,
                                                   summary_prompt)
    from class_factory.utils.load_documents import LessonLoader
    from class_factory.utils.response_parsers import ExtractedRelations
    projectDir = here()
    load_dotenv()

    # Path definitions
    user_home = Path.home()
    readingDir = user_home / os.getenv('readingsDir')
    syllabus_path = user_home / os.getenv('syllabus_path')

    # Example usage
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2,
        max_tokens=None,
        timeout=None,
        max_retries=2,
        api_key=os.getenv('openai_key'),
        organization=os.getenv('openai_org'),
    )

    # llm = Ollama(
    #     model="llama3.1",
    #     temperature=0.2
    # )

    parser = JsonOutputParser(pydantic_object=ExtractedRelations)
    course_name = "American Government"

    validator = Validator(llm=llm)
    loader = LessonLoader(syllabus_path=syllabus_path,
                          reading_dir=readingDir,
                          slide_dir=None)

    # Load documents and lesson objectives
    for lesson_num in range(19, 20):
        lesson_objectives = loader.extract_lesson_objectives(current_lesson=lesson_num)
        documents = loader.load_lessons(lesson_number_or_range=range(lesson_num, lesson_num + 1))

        for document in documents:
            retries = 0
            additional_guidance = ""
            valid = False
            summary = summarize_text(document, prompt=summary_prompt, course_name=course_name, llm=llm)

            combined_template = relationship_prompt
            chain = combined_template | llm | parser

            while not valid and retries < 3:
                response = chain.invoke({'course_name': course_name,
                                         'objectives': lesson_objectives,
                                         'text': document,
                                         'additional_guidance': additional_guidance})

                # Clean and parse the JSON output
                if isinstance(response, str):
                    response_cleaned = response.replace("```json", "").replace("```", "")
                    data = json.loads(response_cleaned)  # This may raise JSONDecodeError
                else:
                    data = response

                # Verify that data is a dict
                if not isinstance(data, dict):
                    raise ValueError("Parsed data is not a dictionary.")

                response_str = json.dumps(response).replace("{", "{{").replace("}", "}}")

                validation_prompt = combined_template.format(course_name=course_name,
                                                             objectives=lesson_objectives,
                                                             text=document,
                                                             additional_guidance=additional_guidance).replace("{", "{{").replace("}", "}}")

                val_response = validator.validate(task_description=validation_prompt,
                                                  generated_response=response_str)

                print(f"validation output: {val_response}")
                # Use overall_score instead of status for validation
                overall_score = val_response.get('overall_score', 0)
                score_threshold = 8.0  # Set your desired threshold
                if overall_score >= score_threshold:
                    valid = True
                else:
                    retries += 1
                    additional_guidance = val_response.get("additional_guidance", "")
                    validator.logger.warning("Validation failed, attempting retry")

            if valid:
                validator.logger.info("Validation succeeded.")
            else:
                raise ValueError("Validation failed after max retries. Ensure correct prompt and input data. Consider use of a different LLM.")

# %%
